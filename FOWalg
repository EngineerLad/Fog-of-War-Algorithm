'''
"Fog-of-War" Machine Learning Algorithm
Takes pre-formatted input and output data to train a model based on spherical Gaussian probability distribution(created using interpolation) in 3 dimensions.
Conceptually, it is a distribution-based clustering algorithm. However, this methodology takes advantage of multi-nodal analysis, 
dynamically expanding centroid area and creating multiple centroid nodes for a more robust algorithm than simply calculating the distance from the calculated centroid based off collected data.
This allows the program to work with less data points while training and still give viable data outputs in the testing and application phase.
The dynamic multi-layered approach allows the program to withstand high-bias, small-size datasets, thus having a high accuracy to data saturation ratio, making it more resilient against overfitting.

Here is a step-by-step breakdown of how this algorithm works:

1. After thorough data formatting, the algorithm receives an array of training data that contains both the conditional variables in the input and the resulting output. (The minimum data point requirement is the number of unique outputs)
2. It performs a data profiling step, which takes the number of variables in the data input array and sets the number of variables that need to be tracked throughout the program's run.
3. Each data point contributes to a general function via compound average probability that directly correlates to a probability field per data input. Each input variable will have one generated function per possible output category.
4. Once the training is complete, the program is left with a general function with the input being the input value and the output is the amplitude of the function given the input value.
5. The output value is divided by the global maximum of that function to get the probability of that input belonging to part of the output's general data profile.
6. Each of those probabilities are cross examined across within each other's same variable types, then the predicted output types for each variable is cross examined with each other to see which output type has the most qualities fulfilled to reach a conclusion.

'''

import numpy as np
import matplotlib.pyplot as plt
import scipy
from scipy import interpolate
import math


class fogofwar():
    def __init__(self, instanceNumber):
        algvar = {
            #numinputvar = number of input variables per datapoint
            "numinputvar" : 0, 
            #numuniqueout = number of unique outcomes based on data profiling
            "numuniqueout" : 0,
            #EXPERIMENTAL YET TO BE ADDED: dynlr = dynamic learning rate. Calculated using the difference in cost per iteration. If the rate of change in cost is positive and increasing, the value increases. If it is instead negative and decreasing, the value decreases.
            # If it is negative/increasing or positive/decreasing, it will remain constant. Learning rates will be a randn generated at initialization.
            #"dynlr" : [],
            #generaleq = general values on a range for the model. places initial and future data points here
            "generaleq":[]


            }

    #deMistify= function that takes a list of datapoints formatted as such: [[input variables here, output variable here],datapoint2,...]. It then processes the information of the given dataset as explained above.
    def deMistify(self,data):
        #gets number of input variables per datapoint
        numinputvar = len(data[0])
        self.algvar["numinputvar"] = numinputvar
        #gets number of unique outputs for the dataset
        outputlist = []
        for i in range(len(data)):
            outputlist.append(data[i][-1])
        uniqueoutputs = np.unique(outputlist)
        numuniqueout = len(uniqueoutputs)
        self.algvar["numuniqueout"] = numuniqueout
        #gets maximum number of decimal points to work with (significant figures, so takes the smallest number of decimal places and rounds the rest of the values based on that and determines the data)
        smallest = 1000000 #kekw i need to work on how to set this value properly
        for i in range(len(data)):
            for j in range(len(data[0])):
                sigfigcount = str(data[i][j])[::-1].find('.')
                if sigfigcount < smallest:
                    smallest = sigfigcount
        #rounds to the sigfig for each value
        for i in range(len(data)):
            for j in range(len(data[0])):
                data[i][j] = round(data[i][j],smallest)

        #calculates a safe range for the program to operate
        largestnumber = 0
        
        for i in range(len(data)):
            for j in range(len(data[0])):
                if abs(data[i][j]) > largestnumber:
                    largestnumber = abs(data[i][j])
                    
        boundsvalue = 0
        if int(math.log10(largestnumber)) == 0:
            boundsvalue = 10**((-1*smallest)+1)
        else:
            boundsvalue = int(math.log10(largestnumber)) + 2
               

        #building a list of the initiation data points from the original data list to start the equations out
        initdatapoint = []

        for i in range(len(data)):
            if data[i][-1] in uniqueoutputs:
                #adds the point containing the output label
                initdatapoint.append(data[i])
                #then removes the point to avoid confusion
                #aka a reminder to MAKE THIS MORE EFFICIENT REEEEEEEEEEE
                uniqueoutputs.remove(data[i][-1])
                
        #remove the points used for the initial data points from the rest of the training dataset
        remainderpoints = data
        for i in range(len(initdatapoint)):
            remainderpoints.remove(initdatapoint[i])

        

        #generate general functions:
        generaleq = []
        eqgroup = []
        #use scipy to make an interpolated spline function for the general solution function. The number of equations needed is the product of the number of inputs and the number of unique outputs.
        #Start with the first datapoint per output as the foundation.
        for i in range(len(initdatapoint)):
            for j in range(len(initdatapoint[i])-1):
                x = np.arange((-1*boundsvalue),boundsvalue,10**(-1*(smallest)))
                y = [0] * boundsvalue*2
                y[int(initdatapoint[i][j])-1] = 1
                eqgroup.append([[x],[y]])
            generaleq.append(eqgroup)
            eqgroup = []
        #the generaleq array has a length that matches the total number of possible outcomes.
        #the eqgroup has a length that matches the total number of input variables


        #Then start analyzing other points

        masterprobabilitylist = []
        probsublist1 = []
        probsublist2 = []
        masterindexlist = []
        subindexlist = []
        #builds a master probability list and a master index list. The MPL keeps record of the probability values for each outcome PER POINT, and the MIL keeps record of what the program thinks should be the outcome
        for i in range(len(remainderpoints)):
            for j in range(len(remainderpoints[i])-1):
                for k in range(generaleq):
                    #this gets the x and y of that particular variable's probabilities
                    x = generaleq[k][j][0]
                    y = generaleq[k][j][1]
                    #this defines the interpolation function
                    interpolator = scipy.interpolate.interp1d(x,y,kind = 'cubic')
                    #this gets the interpolated values, which defines the probability between previously defined points
                    xnew = np.arange(-1*(len(generaleq[k][j][0])),(len(generaleq[k][j][0])),0.001)
                    interpolatedy = interpolator(xnew)
                    #this appends the sublist with the value of the probability for that particular outcome for that variable.
                    probsublist2.append(interpolatedy[remainderpoints[i][j]])
                #this calculates the index of the maximum probability within that sublist
                #this also translates to the index within the possible outcome list of the highest probable outcome based on this particular input variable's value
                maximumcomputedprobableoutcomeindex = np.where(probsublist2 == np.amax(probsublist2))
                #this adds that index to a sublist for indices
                subindexlist.append(maximumcomputedprobableoutcomeindex)

                #this adds the prob sublist to the master list
                probsublist1.append(probsublist2)
                #this clears the sublist
                probsublist2 = []

            # after cycling through ONE datapoint, it adds the subindexlist, whose length is equal to the number of input variables per point, to tha masterindex list, which, at the end, should equal to the number of remaining points.
            masterindexlist.append(subindexlist)
            subindexlist = []
            #REMINDER: the probsublist2 has the length k, which is the number of possible outcomes
            #this sublist contains the liklihood for each output that the datapoint, that this particular input variable belongs to, should be a particular outcome
            #the probsublist1 has the length j, which is the number of input variables
            #this sublist is just a sublist of all the input variables, so we have a list of arrays of the probabilities for each input variable




            #this is where the training begins, where the general equation points are modified based on each additional point
            #training should be iterated per point, so it is placed here

            #first, we get the ground truth value of this point
            GTV = remainderpoints[i][-1]
            #then we find the index of the GTV in the list of possible outcomes
            #this should directly translate to the index of what SHOULD be the highest probability value in the sublist
            indexmain = np.where(uniqueoutputs == GTV)

            #then we use this index within each probability sublist 2 contained in the probability sublist 1 for this particular datapoint to change the value of the probability for this variable towards the ground truth and away from the other outcomes
            #this is also where the cost function is defined(needs fine tuning, but should work(?))
            for i in range(generaleq):
                for j in range(generaleq[0]):
                    if i == indexmain:
                        for k in range(len(remainderpoints[i])-1):
                            generaleq[i][j][1][remainderpoints[i][k]] = probsublist1[j][i] * (1+(1-probsublist1[j][i]))
                    else:
                        for k in range(len(remainderpoints[i])-1):
                            if generaleq[i][j][1][remainderpoints[i][k]] > 0:
                                generaleq[i][j][1][remainderpoints[i][k]] = probsublist1[j][i] * (1+(1-probsublist1[j][i]))


            #finally, the probability sublist 2 is added to the master probability list, which should end with a length that matches the number of remaining points after taking away the calibration points
            masterprobabilitylist.append(probsublist1)
            probsublist1 = []

        #closing the method is appending all the values of the generaleq values to the instance variables
        self.algvar["generaleq"] = generaleq




        






        

